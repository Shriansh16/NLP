{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGwkqbTLH3IAwjiw/sl6/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriansh16/NLP/blob/main/How_to_use_pretrained_word2vec_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5QDOlh2vklQ"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "# Download and load the pre-trained Google News word2vec model\n",
        "google_news_model_path = \"path_to_google_news_model/GoogleNews-vectors-negative300.bin.gz\"\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(google_news_model_path, binary=True, limit=500000)\n",
        "\n",
        "# Load the IMDb dataset\n",
        "# Assume you already have the IMDb dataset loaded as a list of reviews\n",
        "imdb_data = [\n",
        "    \"This movie was fantastic.\",\n",
        "    \"I didn't like this film at all.\",\n",
        "    # More reviews...\n",
        "]\n",
        "\n",
        "# Preprocess the IMDb dataset\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())  # Tokenize the text and convert to lowercase\n",
        "    # Remove stopwords and non-alphanumeric tokens\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]\n",
        "    return tokens\n",
        "\n",
        "imdb_data_preprocessed = [preprocess_text(review) for review in imdb_data]\n",
        "\n",
        "# Function to get word vectors for IMDb dataset\n",
        "def get_word_vectors(tokens):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in word2vec_model:\n",
        "            vectors.append(word2vec_model[token])\n",
        "    return vectors\n",
        "\n",
        "# Convert each review in the IMDb dataset to a sequence of word vectors\n",
        "imdb_vectors = [get_word_vectors(tokens) for tokens in imdb_data_preprocessed]\n",
        "\n",
        "# Now you have IMDb reviews represented as sequences of word vectors\n",
        "# You can use these vectors for various NLP tasks such as sentiment analysis, classification, etc.\n",
        "# Example:\n",
        "# Average the word vectors in each review to get a single vector representation of the review\n",
        "imdb_vectors_avg = [np.mean(review_vectors, axis=0) for review_vectors in imdb_vectors]\n",
        "\n",
        "# Now you can use imdb_vectors_avg for further analysis"
      ]
    }
  ]
}